{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Similarity Scores Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import logging\n",
    "import sys\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import torch\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "logging.getLogger().handlers = []\n",
    "logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read and process query, document, and relevance data\n",
    "df_queries = pd.read_csv('antique_query_test.csv')\n",
    "df_queries = df_queries[['query_id','text']]\n",
    "\n",
    "df_docs = pd.read_csv('antique_sample_404k.csv')\n",
    "df_docs = df_docs[['doc_id','text']]\n",
    "\n",
    "df_qrel = pd.read_csv('antique_qurel_test.csv')\n",
    "df_qrel = df_qrel[['query_id','doc_id','relevance']]\n",
    "\n",
    "# Merge relevant data for query and document\n",
    "merged_df = df_qrel.merge(df_docs, on='doc_id', how='left')\n",
    "\n",
    "# Extract text data from merged DataFrame\n",
    "df_text = merged_df[['doc_id','text']]\n",
    "\n",
    "# Initialize an empty list to store passages\n",
    "passages = []\n",
    "\n",
    "# Iterate through each row in the 'df_text' DataFrame and append text to the 'passages' list\n",
    "for index, row in df_text.iterrows():\n",
    "    passages.append(str(row['text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-computed document embeddings\n",
    "import pickle\n",
    "with open('corpus_embeddings_text_768.pickle', 'rb') as pkl:\n",
    "    doc_embedding = pickle.load(pkl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load pretrained SentenceTransformer: intfloat/e5-base-v2\n",
      "Created a temporary directory at /var/folders/75/0dtb1gc52pdfr40bnpp97qj00000gn/T/tmp4tw5kn7b\n",
      "Writing /var/folders/75/0dtb1gc52pdfr40bnpp97qj00000gn/T/tmp4tw5kn7b/_remote_module_non_scriptable.py\n",
      "Use pytorch device: cpu\n"
     ]
    }
   ],
   "source": [
    "# Initialize SentenceTransformer for embedding\n",
    "bi_encoder = SentenceTransformer('intfloat/e5-base-v2')\n",
    "# bi_encoder.max_seq_length = 512     #Truncate long passages to 512 tokens\n",
    "top_k = 10                          #Number of passages we want to retrieve with the bi-encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(query_id,input_query):  \n",
    "    \n",
    "    data = []\n",
    "\n",
    "    ##### Semantic Search #####\n",
    "    # Encode the query using the bi-encoder and find potentially relevant passages\n",
    "    question_embedding = bi_encoder.encode(input_query, convert_to_tensor=True)\n",
    "    hits = util.semantic_search(question_embedding, doc_embedding, top_k=top_k)\n",
    "    hits = hits[0]  # Get the hits for the first query\n",
    "    \n",
    "    hits = sorted(hits, key=lambda x: x['score'], reverse=True)\n",
    "    for hit in hits:\n",
    "        query_id = query_id\n",
    "        score = hit['score']\n",
    "        text = passages[hit['corpus_id']].replace(\"\\n\", \" \")\n",
    "        doc_id = df_text.iloc[hit['corpus_id']]['doc_id']  # Get the doc_id\n",
    "        \n",
    "        data.append({'query_id': query_id, 'doc_id': doc_id, 'score': score, 'text': text})\n",
    "                \n",
    "    return data  # Return the lists of output scores and passages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe from the output answers\n",
    "df_answers = pd.DataFrame()\n",
    "df_answers['text'] = df_queries.apply(lambda row: search(row['query_id'], row['text']), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[{'query_id': 3990512, 'doc_id': '3265991_12',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[{'query_id': 714612, 'doc_id': '714612_7', 's...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[{'query_id': 2528767, 'doc_id': '2528767_3', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[{'query_id': 821387, 'doc_id': '1082990_5', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[{'query_id': 1880028, 'doc_id': '1880028_0', ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  [{'query_id': 3990512, 'doc_id': '3265991_12',...\n",
       "1  [{'query_id': 714612, 'doc_id': '714612_7', 's...\n",
       "2  [{'query_id': 2528767, 'doc_id': '2528767_3', ...\n",
       "3  [{'query_id': 821387, 'doc_id': '1082990_5', '...\n",
       "4  [{'query_id': 1880028, 'doc_id': '1880028_0', ..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_answers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_dataframe(df):\n",
    "    # Convert the values of the DataFrame to a list\n",
    "    answers = df.values.tolist()\n",
    "\n",
    "    # Create an empty list to store dictionaries from the sublist\n",
    "    dict_list = []\n",
    "\n",
    "    # Iterate through each sublist in the 'answers' list\n",
    "    for sublist in answers:\n",
    "        # Iterate through each dictionary in the sublist\n",
    "        for dictionary in sublist:\n",
    "            # Extend the 'dict_list' with the contents of the current dictionary\n",
    "            dict_list.extend(dictionary)\n",
    "\n",
    "    # Create a new DataFrame from the flattened dictionary list\n",
    "    df_flattened = pd.DataFrame(dict_list)\n",
    "    return df_flattened\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_answers_1 = flatten_dataframe(df_answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query_id</th>\n",
       "      <th>doc_id</th>\n",
       "      <th>score</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3990512</td>\n",
       "      <td>3265991_12</td>\n",
       "      <td>0.874376</td>\n",
       "      <td>concentration</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3990512</td>\n",
       "      <td>2036065_1</td>\n",
       "      <td>0.864214</td>\n",
       "      <td>just by concentration</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3990512</td>\n",
       "      <td>1900286_7</td>\n",
       "      <td>0.853578</td>\n",
       "      <td>It might be harder for concentration..you will...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3990512</td>\n",
       "      <td>248974_2</td>\n",
       "      <td>0.851697</td>\n",
       "      <td>With concentration, you would do something lik...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3990512</td>\n",
       "      <td>311770_3</td>\n",
       "      <td>0.846545</td>\n",
       "      <td>We have to put our mind into whatever we do 'c...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   query_id      doc_id     score  \\\n",
       "0   3990512  3265991_12  0.874376   \n",
       "1   3990512   2036065_1  0.864214   \n",
       "2   3990512   1900286_7  0.853578   \n",
       "3   3990512    248974_2  0.851697   \n",
       "4   3990512    311770_3  0.846545   \n",
       "\n",
       "                                                text  \n",
       "0                                      concentration  \n",
       "1                              just by concentration  \n",
       "2  It might be harder for concentration..you will...  \n",
       "3  With concentration, you would do something lik...  \n",
       "4  We have to put our mind into whatever we do 'c...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_answers_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Store the scores in a csv file\n",
    "df_answers_1 = df_answers_1[['query_id','doc_id','score']]\n",
    "df_answers_1.to_csv('e5_base_v2_scores.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
