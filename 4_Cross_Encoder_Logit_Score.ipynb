{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Encoder Logit Score Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import logging\n",
    "import sys\n",
    "from sentence_transformers import SentenceTransformer, util, CrossEncoder\n",
    "import torch\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "logging.getLogger().handlers = []\n",
    "logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read and process query, document, and relevance data\n",
    "df_queries = pd.read_csv('antique_query_test.csv')\n",
    "df_queries = df_queries[['query_id','text']]\n",
    "\n",
    "df_docs = pd.read_csv('antique_sample_404k.csv')\n",
    "df_docs = df_docs[['doc_id','text']]\n",
    "\n",
    "df_qrel = pd.read_csv('antique_qurel_test.csv')\n",
    "df_qrel = df_qrel[['query_id','doc_id','relevance']]\n",
    "\n",
    "# Merge relevant data for query and document\n",
    "merged_df = df_qrel.merge(df_docs, on='doc_id', how='left')\n",
    "\n",
    "# Extract text data from merged DataFrame\n",
    "df_text = merged_df[['doc_id','text']]\n",
    "\n",
    "# Initialize an empty list to store passages\n",
    "passages = []\n",
    "\n",
    "# Iterate through each row in the 'df_text' DataFrame and append text to the 'passages' list\n",
    "for index, row in df_text.iterrows():\n",
    "    passages.append(str(row['text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-computed document embeddings\n",
    "import pickle\n",
    "with open('corpus_embeddings_text_768.pickle', 'rb') as pkl:\n",
    "    doc_embedding = pickle.load(pkl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load pretrained SentenceTransformer: intfloat/e5-base-v2\n",
      "Use pytorch device: cpu\n",
      "Use pytorch device: cpu\n"
     ]
    }
   ],
   "source": [
    "# Initialize SentenceTransformer for embedding\n",
    "bi_encoder = SentenceTransformer('intfloat/e5-base-v2')\n",
    "# bi_encoder.max_seq_length = 512     #Truncate long passages to 256 tokens\n",
    "top_k = 5                  #Number of passages we want to retrieve with the bi-encoder\n",
    "\n",
    "cross_encoder = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function will search all the articles for passages that\n",
    "# answer the query\n",
    "def search(query_id, input_query):\n",
    "    \n",
    "    data = []\n",
    "    ##### Sematic Search #####\n",
    "    # Encode the query using the bi-encoder and find potentially relevant passages\n",
    "    question_embedding = bi_encoder.encode(input_query, convert_to_tensor=True)\n",
    "    # question_embedding = question_embedding.cuda()\n",
    "    hits = util.semantic_search(question_embedding, doc_embedding, top_k=top_k)\n",
    "    hits = hits[0]  # Get the hits for the first query\n",
    "\n",
    "    ##### Re-Ranking #####\n",
    "    # Now, score all retrieved passages with the cross_encoder\n",
    "    cross_inp = [[input_query, passages[hit['corpus_id']]] for hit in hits]\n",
    "    cross_scores = cross_encoder.predict(cross_inp)\n",
    "\n",
    "    # Sort results by the cross-encoder scores\n",
    "    for idx in range(len(cross_scores)):\n",
    "        hits[idx]['cross-score'] = cross_scores[idx]\n",
    "\n",
    "    # Output of top-10 hits from re-ranker\n",
    "    hits = sorted(hits, key=lambda x: x['cross-score'], reverse=True)\n",
    "    for hit in hits[0:top_k]:\n",
    "        query_id = query_id\n",
    "        cross_score = hit['cross-score']\n",
    "        text = passages[hit['corpus_id']].replace(\"\\n\", \" \")\n",
    "        doc_id = df_text.iloc[hit['corpus_id']]['doc_id']  # Get the doc_id\n",
    "        data.append({'query_id': query_id, 'doc_id': doc_id, 'score': cross_score, 'text':text})\n",
    "        \n",
    "    return data  # Return the lists of output scores and passages\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe from the output answers\n",
    "df_answers = pd.DataFrame()\n",
    "df_answers['text'] = df_queries.apply(lambda row: search(row['query_id'], row['text']), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[{'query_id': 3990512, 'doc_id': '248974_2', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[{'query_id': 714612, 'doc_id': '714612_0', 's...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[{'query_id': 2528767, 'doc_id': '2528767_3', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[{'query_id': 821387, 'doc_id': '821387_3', 's...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[{'query_id': 1880028, 'doc_id': '1880028_0', ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  [{'query_id': 3990512, 'doc_id': '248974_2', '...\n",
       "1  [{'query_id': 714612, 'doc_id': '714612_0', 's...\n",
       "2  [{'query_id': 2528767, 'doc_id': '2528767_3', ...\n",
       "3  [{'query_id': 821387, 'doc_id': '821387_3', 's...\n",
       "4  [{'query_id': 1880028, 'doc_id': '1880028_0', ..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_answers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_dataframe(df):\n",
    "    # Convert the values of the DataFrame to a list\n",
    "    answers = df.values.tolist()\n",
    "\n",
    "    # Create an empty list to store dictionaries from the sublist\n",
    "    dict_list = []\n",
    "\n",
    "    # Iterate through each sublist in the 'answers' list\n",
    "    for sublist in answers:\n",
    "        # Iterate through each dictionary in the sublist\n",
    "        for dictionary in sublist:\n",
    "            # Extend the 'dict_list' with the contents of the current dictionary\n",
    "            dict_list.extend(dictionary)\n",
    "\n",
    "    # Create a new DataFrame from the flattened dictionary list\n",
    "    df_flattened = pd.DataFrame(dict_list)\n",
    "    return df_flattened"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_answers_1 = flatten_dataframe(df_answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query_id</th>\n",
       "      <th>doc_id</th>\n",
       "      <th>score</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3990512</td>\n",
       "      <td>248974_2</td>\n",
       "      <td>-4.451635</td>\n",
       "      <td>With concentration, you would do something lik...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3990512</td>\n",
       "      <td>311770_3</td>\n",
       "      <td>-5.209757</td>\n",
       "      <td>We have to put our mind into whatever we do 'c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3990512</td>\n",
       "      <td>1900286_7</td>\n",
       "      <td>-5.772523</td>\n",
       "      <td>It might be harder for concentration..you will...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3990512</td>\n",
       "      <td>3265991_12</td>\n",
       "      <td>-6.118735</td>\n",
       "      <td>concentration</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3990512</td>\n",
       "      <td>2036065_1</td>\n",
       "      <td>-7.254282</td>\n",
       "      <td>just by concentration</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   query_id      doc_id     score  \\\n",
       "0   3990512    248974_2 -4.451635   \n",
       "1   3990512    311770_3 -5.209757   \n",
       "2   3990512   1900286_7 -5.772523   \n",
       "3   3990512  3265991_12 -6.118735   \n",
       "4   3990512   2036065_1 -7.254282   \n",
       "\n",
       "                                                text  \n",
       "0  With concentration, you would do something lik...  \n",
       "1  We have to put our mind into whatever we do 'c...  \n",
       "2  It might be harder for concentration..you will...  \n",
       "3                                      concentration  \n",
       "4                              just by concentration  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_answers_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_answers_1 = df_answers_1[['query_id','doc_id','score']]\n",
    "df_answers_1.to_csv('Cross_encoder_e5_base_v2_scores.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
