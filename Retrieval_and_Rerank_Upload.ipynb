{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieval_and_Rerank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the Documents for Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"ANTIQUE is a non-factoid quesiton answering dataset based on the questions and answers of Yahoo! Webscope L6.\" \n",
    "# on \"https://ir-datasets.com/antique.html\"\n",
    "# Documents: Short answer passages (from Yahoo Answers)\n",
    "# Queries: Natural language questions (from Yahoo Answers)\n",
    "\n",
    "#Read the csv file\n",
    "df = pd.read_csv('antique_sample_404k.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 403666 entries, 0 to 403665\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count   Dtype \n",
      "---  ------      --------------   ----- \n",
      " 0   Unnamed: 0  403666 non-null  int64 \n",
      " 1   doc_id      403666 non-null  object\n",
      " 2   text        403662 non-null  object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 9.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combining the document id and the document text\n",
    "df['comb_text'] = df['doc_id'] + ', ' + df['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting all the rows to string datatype\n",
    "df1 = df[['comb_text']].astype(str) #.head(5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Appending each document into a list\n",
    "passages = []\n",
    "for index, row in df.iterrows():\n",
    "    passages.append(str(row['comb_text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "print(type(passages))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"2020338_0, A small group of politicians believed strongly that the fact that Saddam Hussien remained in power after the first Gulf War was a signal of weakness to the rest of the world, one that invited attacks and terrorism. Shortly after taking power with George Bush in 2000 and after the attack on 9/11, they were able to use the terrorist attacks to justify war with Iraq on this basis and exaggerated threats of the development of weapons of mass destruction. The military strength of the U.S. and the brutality of Saddam's regime led them to imagine that the military and political victory would be relatively easy.\",\n",
       " '2020338_1, Because there is a lot of oil in Iraq.',\n",
       " '2020338_2, It is tempting to say that the US invaded Iraq because it has lots of oil, but the US is not a country in a deep economic problem that capturing other country’s oil is an actual need for survival. It is more likely that the Iraq invading Kuwait scenario would fall under that assumption.. I think that the US government has come to a conclusion that we are on the verge of a war of religions, or more likely ideologies. It would be presumptuous to try and determent a one cause to the coming war. . I think that the world wide spread of the media with its many forms (Cable, Satellite, Internet, etc.)  have pushed the Moslem regimes to the extreme, fearing that secularity and democratic influence is penetrating their country and will result in an up raising against them. One of the best way to maintain the power that you have and even gain more of it, is by hatred. When the common man is occupied hating an outside enemy, its hatred is kept out side the county and would not be directed towards the regime. . So- I believe that the US understands that the fanatic Moslem regimes have already started a war on the democratic world and now is the time to try a fight it.. . So why invade Iraq? Because it is a huge, week Moslem country that thought to be easy to defeat. . This is exactly the same reason why Afghanistan was first and Syria is next in line.',\n",
       " '2020338_3, I think Yuval is pretty spot on. It\\'s a proving ground and a focal point for terror activity that\\'s not on American soil. And, because no one liked Saddam Hussein, no other countries (even in the Middle East) were about to rise up and join his side.. . Rabid speculation: now the Pentagon has a model that says it takes ~5 years, ~$200B and ~2,000 casualties to \"rebuild\" a dictatorship into a democracy. Who\\'s next on the list?',\n",
       " '2874684_0, Call an area apiarist.  They should be able to help you and would most likely remove them at no charge in exchange for the hive.  The bees have value and they now belong to you.',\n",
       " \"2874684_1, Don't try this yourself but this is what the old fashioned way is - done in some villages in other parts of the world.. . The guy who dismantles, wears a mask with holes at the eyes so he can see, carries a big sack with burning coals in it.  He also wraps his hands with thick cloths, carries an empty bag to collect the honey in it.. He then collects the honey in the empty bag, pulls the hive into the bag of coals.. . If he just wants to collect the honey, he would leave after collecting the honey - but the bag of coals is used to choke & burn the bees if he wanted to get rid of the hive.. . That's a bit like coding in COBOL & assembly :)\",\n",
       " \"4193114_0, There's a general belief in Europe (and in fact elsewhere in the world, such as China) that it's unhealthy to drink water with a meal because it dilutes the digestive juices. Wine is OK because it stimulates digestion, and mineral waters are also considered digestives.. . In general, Europeans are much more concerned with the digestive process than Americans.\",\n",
       " '4193114_1, I\\'d like to take a different approach in answering this. I think geographical location and higher availability of other drinks probably is a bigger reason that water is not consumed as much by people in certain regions, including Europe. I believe and many visitors have commented that children drink less water and more soda in USA.  This is primarily due to the fact that soda companies advertise a lot, making it more attractive. Secondly, SODA IS ATTRACTIVE, and according to a few medical experts it\\'s even addictive (yes, caffeine is addictive to some extent).  . . Secondly the cold weather in upper northern hemisphere in general is more of a reason that ppl drink less water and more of other drinks.  For example if you are from a tropical country or from a very humid place, you would probably & naturally  be drinking more water rather than if you are from   a country like Austria, Switzerland, Denmark, Finland.. . Another reason is that people being less immune to impure water (like tap water) and being more dependent on bottled water makes the water less affordable and less available.  If you need to pay  extra or need to work harder to get the commodity, you may resort to cheaper commodity or a near by commodity.. . Another reason I also feel is the commute using Cars rather than walking or cycling.  If you walk more to commute (like walk to train stations, walk a few blocks to get groceries, etc.) then you are more likely to drink water when compared to driving to every place you go and exert yourself much less.  In many other countries people walk, walk and walk for several small things.. . Lack of education and awareness is also a reason for not consuming enough water. Not many people (except for few educated ones)know that 80% of our body is water.  Even if they knew, ppl forget that fact easily and resort to \"other drinks\".. . There are simply several reasons or combination of reasons for not consuming enough water by the people in general.. . Finally, after having said all this,. Beer Happens!',\n",
       " \"1908421_0, hybrid cars save energy in two ways: 1.by storing energy from the breaks2.by engaging the gas motor only in it's most effective work RPM meaning that the system will engage the gas motor mostly at coursing speed (close to the most efficient motor RPM)Having said the above, driving in the city almost never gets you to the efficient RPM.Also- it is true that the same energy that is being stored in the cars' battery needed to be generated by chemic energy. The cool thing about it is that the pollution can be outside of the city and not in the city. (Like in San Francisco, the electric buses generate the same pollution as a gas buses it is just not in the city.You can also add that electric engines are much quieter then gas engines.So- all in all- I the hybrid benefits are more visible in city driving\",\n",
       " '1908421_1, The gas mileage for some hybrids is better in the city because they spend more time using their electric motor instead of their gas engine.  Most hybrids have battery packs which are charged by what is called \"generative breaking\".  Instead of slowing down with traditional braking, these cars store some of the energy from braking into a battery pack.  Then when the light changes and the car moves again, the energy stored in the battery can be used to move the car, or assist the engine in moving the car.. . In the city this effect can be more pronounced because of more frequent stopping and starting.']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "passages[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding the Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from sentence_transformers import SentenceTransformer, CrossEncoder, util\n",
    "import gzip\n",
    "import os\n",
    "import torch\n",
    "\n",
    "bi_encoder = SentenceTransformer('multi-qa-MiniLM-L6-cos-v1')\n",
    "bi_encoder.max_seq_length = 256     #Truncate long passages to 256 tokens\n",
    "top_k = 32                          #Number of passages we want to retrieve with the bi-encoder\n",
    "\n",
    "#The bi-encoder will retrieve 32 documents. We use a cross-encoder, to re-rank the results list to improve the quality\n",
    "cross_encoder = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-6-v2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff5f20b7a72e4f9c854107d6f968dac1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/12615 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Embedding the documents using Bi-Encoder\n",
    "corpus_embeddings = bi_encoder.encode(passages, convert_to_tensor=True, show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Store the corpus_embeddings as pickle file for backup\n",
    "import pickle\n",
    "with open('corpus_embeddings.pickle', 'wb') as pkl:\n",
    "    pickle.dump(corpus_embeddings, pkl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the corpus_embeddings.pickle file\n",
    "import pickle\n",
    "with open('corpus_embeddings.pickle', 'rb') as pkl:\n",
    "    doc_embedding = pickle.load(pkl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76fe6b98808e4429ace7d77e87258c85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/403666 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# We also compare the results to lexical search (keyword search). Here, we use \n",
    "# the BM25 algorithm which is implemented in the rank_bm25 package.\n",
    "\n",
    "from rank_bm25 import BM25Okapi\n",
    "from sklearn.feature_extraction import _stop_words\n",
    "import string\n",
    "from tqdm.autonotebook import tqdm\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# We lower case our text and remove stop-words from indexing\n",
    "def bm25_tokenizer(text):\n",
    "    tokenized_doc = []\n",
    "    for token in text.lower().split():\n",
    "        token = token.strip(string.punctuation)\n",
    "\n",
    "        if len(token) > 0 and token not in _stop_words.ENGLISH_STOP_WORDS:\n",
    "            tokenized_doc.append(token)\n",
    "    return tokenized_doc\n",
    "\n",
    "\n",
    "tokenized_corpus = []\n",
    "for passage in tqdm(passages):\n",
    "    tokenized_corpus.append(bm25_tokenizer(passage))\n",
    "\n",
    "bm25 = BM25Okapi(tokenized_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function will search all the articles for passages that\n",
    "# answer the query\n",
    "def search(query):\n",
    "    print(\"Input question:\", query)\n",
    "\n",
    "    ##### BM25 search (lexical search) #####\n",
    "    bm25_scores = bm25.get_scores(bm25_tokenizer(query))\n",
    "    top_n = np.argpartition(bm25_scores, -5)[-5:]\n",
    "    bm25_hits = [{'corpus_id': idx, 'score': bm25_scores[idx]} for idx in top_n]\n",
    "    bm25_hits = sorted(bm25_hits, key=lambda x: x['score'], reverse=True)\n",
    "    \n",
    "    print(\"Top-3 lexical search (BM25) hits\")\n",
    "    for hit in bm25_hits[0:3]:\n",
    "        print(\"\\t{:.3f}\\t{}\".format(hit['score'], passages[hit['corpus_id']].replace(\"\\n\", \" \")))\n",
    "        \n",
    "\n",
    "    ##### Sematic Search #####\n",
    "    # Encode the query using the bi-encoder and find potentially relevant passages\n",
    "    question_embedding = bi_encoder.encode(query, convert_to_tensor=True)\n",
    "    # question_embedding = question_embedding.cuda()\n",
    "    hits = util.semantic_search(question_embedding, doc_embedding, top_k=top_k)\n",
    "    hits = hits[0]  # Get the hits for the first query\n",
    "\n",
    "    ##### Re-Ranking #####\n",
    "    # Now, score all retrieved passages with the cross_encoder\n",
    "    cross_inp = [[query, passages[hit['corpus_id']]] for hit in hits]\n",
    "    cross_scores = cross_encoder.predict(cross_inp)\n",
    "\n",
    "    # Sort results by the cross-encoder scores\n",
    "    for idx in range(len(cross_scores)):\n",
    "        hits[idx]['cross-score'] = cross_scores[idx]\n",
    "\n",
    "    # Output of top-5 hits from bi-encoder\n",
    "    print(\"\\n-------------------------\\n\")\n",
    "    print(\"Top-3 Bi-Encoder Retrieval hits\")\n",
    "    hits = sorted(hits, key=lambda x: x['score'], reverse=True)\n",
    "    for hit in hits[0:3]:\n",
    "        print(\"\\t{:.3f}\\t{}\".format(hit['score'], passages[hit['corpus_id']].replace(\"\\n\", \" \")))\n",
    "\n",
    "    # Output of top-5 hits from re-ranker\n",
    "    print(\"\\n-------------------------\\n\")\n",
    "    print(\"Top-3 Cross-Encoder Re-ranker hits\")\n",
    "    hits = sorted(hits, key=lambda x: x['cross-score'], reverse=True)\n",
    "    for hit in hits[0:3]:\n",
    "        print(\"\\t{:.3f}\\t{}\".format(hit['cross-score'], passages[hit['corpus_id']].replace(\"\\n\", \" \")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input question: What causes severe swelling and pain in the knees?\n",
      "Top-3 lexical search (BM25) hits\n",
      "\t22.685\t3241109_2, Indomethacin is an anaglesic used for moderate to severe arthritis.. It aids in the reduction of swelling and pain.\n",
      "\t19.330\t2606613_0, In a mild wrist sprain maybe slightly swollen and tender. And probably feel mild pain when you move it.. .      Severe pain swelling can change the shape of your wrist and you can may have some bruising (a black and blue discoloration)\n",
      "\t19.323\t2818197_2, Tweety bird is right on.  I had one yesterday and aside from tenderness, I am fine.  Just make sure there is no severe pain, swelling or redness at the sight where the biopsy was done.\n",
      "\n",
      "-------------------------\n",
      "\n",
      "Top-3 Bi-Encoder Retrieval hits\n",
      "\t0.756\t3097310_4, I'm not sure about your other problems, but the only time my knees swell and hurt is when I pull and stretch the tendons.\n",
      "\t0.709\t1658637_2, ahhh i had same problem once. I went to the dr's and i had lots of fluid around my knee. They just gave me tablets to make the swelling go down. this may not be ur cause but i'd presume its because u do actually stand and move a lot during your work hun.\n",
      "\t0.701\t2101840_0, The muscles around your knees may be inflammed.  If it happens a lot, have your doctor check it out.\n",
      "\n",
      "-------------------------\n",
      "\n",
      "Top-3 Cross-Encoder Re-ranker hits\n",
      "\t2.898\t4204097_0, Many times it's not caused by an injury but can be caused by a person being overweight and putting too much pressure on the cartilage which compresses it causing extreme pain in the knee when walking.  Can be corrected with knee replacement surgery.\n",
      "\t1.449\t1167999_1, The reply from \"Need an answer\" describes osteoporosis.  Osteoarthritis is a degenerative joint disease that can cause pain and stiffness in larger joints, such as the knees.  The cartilage breaks down and does not glide smoothly when the joint is bent.  Depending on the degree of degeneration, often obtained through an MRI, your doctor will typically prescribe medication, physical therapy, cortisone injections, and/or arthroscopic surgery.\n",
      "\t-0.104\t1658637_4, The nature of your work may be a factor for your knee pain. The pain may have been brought about by your frequent standing and moving, which may have strained and/or destroyed the structures surrounding and supporting your knee (muscles, ligaments, etc). When exactly did it start hurting and what were you doing when it hurt?. . The best thing to do is to see an orthopedic doctor immediately before your condition worsens. You may avail of physical therapy services to assist in addressing your knee pain and modify your work environment/requirements. If you can't have a check up right away, try putting ice on your knee for the first 24-48 hours or until the swelling decreases, then apply warm compress after for about 20-30 minutes thrice a day. But again, go have a check-up as soon as you can.. . As for your mom (how old is she?), it's a part of the aging process for older adults to experience joint pains especially in the knees, spine, hips, and wrists. This may be due to diseases such as rheumatoid or osteoarthritis, but again, she should consult a doctor for the right diagnosis and for proper treatment.\n"
     ]
    }
   ],
   "source": [
    "search(query = \"What causes severe swelling and pain in the knees?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the Testing Queries\n",
    "df_query_test = pd.read_csv('antique_query_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_query_test = df_query_test[['query_id','text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_cross_encoder(input_query):\n",
    "    ##### Sematic Search #####\n",
    "    # Encode the query using the bi-encoder and find potentially relevant passages\n",
    "    question_embedding = bi_encoder.encode(input_query, convert_to_tensor=True)\n",
    "    # question_embedding = question_embedding.cuda()\n",
    "    hits = util.semantic_search(question_embedding, doc_embedding, top_k=top_k)\n",
    "    hits = hits[0]  # Get the hits for the first query\n",
    "\n",
    "    ##### Re-Ranking #####\n",
    "    # Now, score all retrieved passages with the cross_encoder\n",
    "    cross_inp = [[input_query, passages[hit['corpus_id']]] for hit in hits]\n",
    "    cross_scores = cross_encoder.predict(cross_inp)\n",
    "\n",
    "    # Sort results by the cross-encoder scores\n",
    "    for idx in range(len(cross_scores)):\n",
    "        hits[idx]['cross-score'] = cross_scores[idx]\n",
    "\n",
    "    # Output of top hit from re-ranker\n",
    "    print(\"\\n-------------------------\\n\")\n",
    "    print(\"Top-3 Cross-Encoder Re-ranker hits\")\n",
    "    hits = sorted(hits, key=lambda x: x['cross-score'], reverse=True)\n",
    "    for hit in hits[0:1]:\n",
    "        output_answer = passages[hit['corpus_id']].replace(\"\\n\", \" \")\n",
    "        # print(\"\\t{:.3f}\\t{}\".format(hit['cross-score'], passages[hit['corpus_id']].replace(\"\\n\", \" \")))\n",
    "        return output_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-------------------------\n",
      "\n",
      "Top-3 Cross-Encoder Re-ranker hits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"714612_0, This goes along with the question of why don't we fall off the earth if it is round. The answer is because gravity is holding us (and the water) down.\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_cross_encoder(input_query = \"Why doesn't the water fall off  earth if it's round?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting answers for all the test queries\n",
    "df_query_test['result'] = df_query_test['text'].apply(search_cross_encoder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_query_test.to_csv('test_answers.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Seperating the doc_id from the retrieved answers\n",
    "import re\n",
    "df_query_test['doc_id'] = df_query_test['result'].apply(lambda x: re.search(r'(\\d+_?\\d*)', x).group(1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading the Query Relevance File\n",
    "df_qrel_test = pd.read_csv('antique_qurel_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_qrel_test = df_qrel_test[['query_id','doc_id', 'relevance']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Only considering the Query and Answer pair with highest relevance\n",
    "relevant_instances = df_qrel_test[df_qrel_test['relevance'].isin([4])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query_id</th>\n",
       "      <th>doc_id</th>\n",
       "      <th>relevance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1964316</td>\n",
       "      <td>1964316_5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1964316</td>\n",
       "      <td>1964316_3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1964316</td>\n",
       "      <td>1964316_2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1964316</td>\n",
       "      <td>1964316_0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1964316</td>\n",
       "      <td>369616_4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6565</th>\n",
       "      <td>1262692</td>\n",
       "      <td>1262692_3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6567</th>\n",
       "      <td>1262692</td>\n",
       "      <td>1262692_5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6568</th>\n",
       "      <td>1262692</td>\n",
       "      <td>1262692_6</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6572</th>\n",
       "      <td>1262692</td>\n",
       "      <td>986052_4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6577</th>\n",
       "      <td>1262692</td>\n",
       "      <td>866587_0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1334 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      query_id     doc_id  relevance\n",
       "0      1964316  1964316_5          4\n",
       "8      1964316  1964316_3          4\n",
       "9      1964316  1964316_2          4\n",
       "11     1964316  1964316_0          4\n",
       "29     1964316   369616_4          4\n",
       "...        ...        ...        ...\n",
       "6565   1262692  1262692_3          4\n",
       "6567   1262692  1262692_5          4\n",
       "6568   1262692  1262692_6          4\n",
       "6572   1262692   986052_4          4\n",
       "6577   1262692   866587_0          4\n",
       "\n",
       "[1334 rows x 3 columns]"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relevant_instances "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_ground_truth_df = relevant_instances[['query_id','doc_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_predictions_df = df_query_test[['query_id','doc_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import recall_score\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_predictions_df = eval_predictions_df.drop_duplicates(subset='query_id')\n",
    "eval_ground_truth_df = eval_ground_truth_df.drop_duplicates(subset='query_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: 0.125\n"
     ]
    }
   ],
   "source": [
    "# Merge the two dataframes on 'query_id' to align ground truth and predictions\n",
    "merged_df = eval_predictions_df.merge(eval_ground_truth_df, on='query_id', how='left', suffixes=('_pred', '_truth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query_id</th>\n",
       "      <th>doc_id_pred</th>\n",
       "      <th>doc_id_truth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3990512</td>\n",
       "      <td>3931664_2</td>\n",
       "      <td>3990512_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>714612</td>\n",
       "      <td>714612_0</td>\n",
       "      <td>714612_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2528767</td>\n",
       "      <td>2528767_3</td>\n",
       "      <td>2528767_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>821387</td>\n",
       "      <td>821387_3</td>\n",
       "      <td>821387_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1880028</td>\n",
       "      <td>1880028_0</td>\n",
       "      <td>1880028_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>2192891</td>\n",
       "      <td>2192891_1</td>\n",
       "      <td>2192891_7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>4406669</td>\n",
       "      <td>209084_8</td>\n",
       "      <td>4406669_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>1582877</td>\n",
       "      <td>1582877_14</td>\n",
       "      <td>1582877_14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>1340574</td>\n",
       "      <td>1340574_2</td>\n",
       "      <td>1340574_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>1971899</td>\n",
       "      <td>4287782_0</td>\n",
       "      <td>1971899_0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     query_id doc_id_pred doc_id_truth\n",
       "0     3990512   3931664_2    3990512_1\n",
       "1      714612    714612_0     714612_0\n",
       "2     2528767   2528767_3    2528767_2\n",
       "3      821387    821387_3     821387_0\n",
       "4     1880028   1880028_0    1880028_3\n",
       "..        ...         ...          ...\n",
       "195   2192891   2192891_1    2192891_7\n",
       "196   4406669    209084_8    4406669_2\n",
       "197   1582877  1582877_14   1582877_14\n",
       "198   1340574   1340574_2    1340574_0\n",
       "199   1971899   4287782_0    1971899_0\n",
       "\n",
       "[200 rows x 3 columns]"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = merged_df['doc_id_truth'].tolist()\n",
    "y_pred = merged_df['doc_id_pred'].tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "recall_metric = evaluate.load(\"recall\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'recall': 0.125}\n"
     ]
    }
   ],
   "source": [
    "#Recall score\n",
    "recall_score = recall_metric.compute(references=y_test, predictions=y_pred, average='micro')\n",
    "print(recall_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
