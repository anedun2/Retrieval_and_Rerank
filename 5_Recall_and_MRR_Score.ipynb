{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "96UdviYxbznu"
      },
      "source": [
        "# Recall and MRR Score Calculation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "RJ1BhNmm8XKb"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "4wTJIPd78mbh"
      },
      "outputs": [],
      "source": [
        "#importing the query relevance file\n",
        "df_qrel = pd.read_csv('antique_qurel_test.csv')\n",
        "df_qrel = df_qrel[['query_id','doc_id','relevance']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "K56o5RVB9_mR"
      },
      "outputs": [],
      "source": [
        "# Define a function to map relevance values to binary labels\n",
        "def map_values(value):\n",
        "    if value in [3, 4]:\n",
        "        return 1\n",
        "    else:\n",
        "        return 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "_reQURQh-PEV",
        "outputId": "25b74302-308c-4949-9dad-5c486d463f8f"
      },
      "outputs": [],
      "source": [
        "# Apply the mapping function to create binary labels and add to the relevance data\n",
        "df_qrel['label'] = df_qrel['relevance'].apply(map_values)\n",
        "\n",
        "# Drop duplicate entries based on query_id and doc_id in the relevance data\n",
        "df_qrel = df_qrel.drop_duplicates(subset=['query_id','doc_id'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BWXJkm1y_cTU"
      },
      "source": [
        "## Recall Calculation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_b4ss0DrtpWu"
      },
      "outputs": [],
      "source": [
        "df_qrel = df_qrel[['query_id','doc_id','label']]\n",
        "\n",
        "score_df = pd.read_csv('e5_base_v2_scores.csv')\n",
        "score_df = score_df[['query_id','doc_id']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3jXqioelxgS2"
      },
      "outputs": [],
      "source": [
        "def calculate_average_recall(score_df, df_qrel):\n",
        "    # Drop duplicates based on 'query_id' and 'doc_id'\n",
        "    df = score_df.drop_duplicates(subset=['query_id', 'doc_id'])\n",
        "\n",
        "    # Merge with df_qrel to get matching documents between predicted and qrel file\n",
        "    common_ids_df = pd.merge(df, df_qrel, on=['query_id', 'doc_id'], how='inner')\n",
        "\n",
        "    # Count occurrences of matching documents between predicted and qrel file\n",
        "    query_id_counts = common_ids_df.groupby('query_id')['query_id'].count().reset_index(name='row_count')\n",
        "\n",
        "    # Count occurrences of doc_id for each query_id in df_qrel\n",
        "    doc_count_per_query = df_qrel.groupby('query_id')['doc_id'].count().reset_index(name='doc_count')\n",
        "\n",
        "    # Merge the two count DataFrames\n",
        "    recall_df = pd.merge(query_id_counts, doc_count_per_query, on=['query_id'], how='inner')\n",
        "\n",
        "    # Calculate recall for each query_id\n",
        "    recall_df['recall'] = recall_df['row_count'] / recall_df['doc_count']\n",
        "\n",
        "    # Calculate average recall\n",
        "    average_recall = sum(recall_df['recall']) / len(df_qrel['query_id'].unique())\n",
        "\n",
        "    return average_recall\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qGVjCgFexqyT",
        "outputId": "ed7b46f9-c3ab-4917-cf4c-17913a5e45b5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average Recall = 0.7510839138058918\n"
          ]
        }
      ],
      "source": [
        "avg_recall_result = calculate_average_recall(score_df, df_qrel)\n",
        "print(\"Average Recall =\", avg_recall_result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WDVBJsBN8z2T"
      },
      "source": [
        "## MRR Calculation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "ImaQ-X9H9mf9"
      },
      "outputs": [],
      "source": [
        "cross_enc_score_df = pd.read_csv('Cross_encoder_e5_base_v2_scores.csv')\n",
        "cross_enc_score_df = cross_enc_score_df[['query_id','doc_id']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "bMByQHy4uIj1"
      },
      "outputs": [],
      "source": [
        "\n",
        "def calculate_mrr(dataframe, df_qrel):\n",
        "    # Filtering rows with label values as 1\n",
        "    filtered_df = df_qrel[df_qrel['label'] == 1]\n",
        "\n",
        "    # Creating a new 'rank' column based on 'query_id'\n",
        "    dataframe['rank'] = dataframe.groupby('query_id').cumcount() + 1\n",
        "    \n",
        "    # Merging with filtered_df and filling NaNs with 0\n",
        "    labeled_search_results = dataframe.merge(filtered_df, how='left', on=['query_id', 'doc_id']).fillna(0)\n",
        "    \n",
        "    # Grouping by query_id and label to find the minimum rank for each relevance level\n",
        "    relevances_rank = labeled_search_results.groupby(['query_id', 'label'])['rank'].min()\n",
        "    \n",
        "    # Extracting ranks where label is 1 (relevant)\n",
        "    ranks = relevances_rank.loc[:, 1]\n",
        "    \n",
        "    # Calculating reciprocal ranks\n",
        "    reciprocal_ranks = 1 / ranks\n",
        "    \n",
        "    # Calculating MRR\n",
        "    mrr = sum(reciprocal_ranks) / len(dataframe['query_id'].unique())\n",
        "    \n",
        "    return mrr\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iG6-eyshuM5O",
        "outputId": "4a89baef-e7d4-4204-96d4-d75d7ef1385e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MRR = 0.8654285714285714\n"
          ]
        }
      ],
      "source": [
        "mrr_result = calculate_mrr(cross_enc_score_df, df_qrel)\n",
        "print(\"MRR =\", mrr_result)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
